import os
from datetime import datetime
import uuid
import pandas as pd
import xml.etree.ElementTree as ET
from flask import Flask, request
from google.cloud import storage
from google.cloud import bigquery
from google.api_core import exceptions
import json

# --- Configura√ß√µes do BigQuery ---
PROJECT_ID = "sud-leather"
DATASET_ID = "RAW_DATA"
TABLE_ID = "Frigorifico_Nota_Fiscal"

# Inicializa os clientes do Cloud Storage e BigQuery
storage_client = storage.Client()
bigquery_client = bigquery.Client(project=PROJECT_ID)

app = Flask(__name__)

def get_element_text(element, path, namespaces, default=None):
    """
    Fun√ß√£o auxiliar para encontrar um sub-elemento e retornar o seu texto.
    Retorna um valor padr√£o se o elemento n√£o for encontrado.
    """
    if element is None:
        return default
    found_element = element.find(path, namespaces)
    if found_element is not None and found_element.text is not None:
        return found_element.text.strip()
    return default

def criar_df_nfe(xml_content):
    """
    Processa o conte√∫do de um XML de NFe de forma robusta e retorna um DataFrame.
    """
    try:
        namespaces = {'nfe': 'http://www.portalfiscal.inf.br/nfe'}
        root = ET.fromstring(xml_content)
        infNFe = root.find('.//nfe:infNFe', namespaces)

        if infNFe is None:
            print("‚ùå Tag <infNFe> n√£o encontrada no XML.")
            return None

        # --- Extra√ß√£o de dados do cabe√ßalho da NFe (de forma segura) ---
        ide_element = infNFe.find('nfe:ide', namespaces)
        emit_element = infNFe.find('nfe:emit', namespaces)
        transp_element = infNFe.find('nfe:transp', namespaces)

        if ide_element is None:
            print("‚ùå Tag essencial <ide> n√£o encontrada.")
            return None
        if emit_element is None:
            print("‚ùå Tag essencial <emit> n√£o encontrada.")
            return None

        # Valida√ß√£o campo a campo para logs mais claros
        numero_nf = get_element_text(ide_element, 'nfe:nNF', namespaces)
        if not numero_nf:
            print("‚ùå Campo obrigat√≥rio n√£o encontrado no XML: nNF (N√∫mero da Nota Fiscal)")
            return None

        data_emissao_str = get_element_text(ide_element, 'nfe:dhEmi', namespaces) or get_element_text(ide_element, 'nfe:dEmi', namespaces)
        if not data_emissao_str:
            print("‚ùå Campo obrigat√≥rio n√£o encontrado no XML: dhEmi ou dEmi (Data de Emiss√£o)")
            return None
            
        emitente_nome = get_element_text(emit_element, 'nfe:xNome', namespaces)
        if not emitente_nome:
            print("‚ùå Campo obrigat√≥rio n√£o encontrado no XML: xNome (Nome do Emitente)")
            return None

        emitente_cnpj = get_element_text(emit_element, 'nfe:CNPJ', namespaces)
        if not emitente_cnpj:
            print("‚ùå Campo obrigat√≥rio n√£o encontrado no XML: CNPJ (CNPJ do Emitente)")
            return None

        qvol_text = get_element_text(transp_element, 'nfe:vol/nfe:qVol', namespaces, '0')
        quantidade_pecas = int(float(qvol_text))

        # Formata a data de emiss√£o
        date_str_sem_fuso = data_emissao_str.split('T')[0]
        data_emissao_formatada = datetime.strptime(date_str_sem_fuso, '%Y-%m-%d').date()

        # --- Extra√ß√£o dos itens da NFe ---
        lista_produtos = []
        for det in infNFe.findall('.//nfe:det', namespaces):
            prod_element = det.find('nfe:prod', namespaces)
            if prod_element is None:
                continue # Pula para o pr√≥ximo item se a tag <prod> n√£o existir

            produto = {
                # --- CORRE√á√ÉO: numero_nf como STRING ---
                'numero_nf': numero_nf,
                'data_emissao': data_emissao_formatada,
                'emitente': emitente_nome,
                # --- CORRE√á√ÉO: CNPJ como STRING (o tipo num√©rico foi removido mais abaixo) ---
                'CNPJ': emitente_cnpj,
                'Descricao': get_element_text(prod_element, 'nfe:xProd', namespaces, ''),
                'Quantidade_pcs': quantidade_pecas,
                'Quantidade_kg': float(get_element_text(prod_element, 'nfe:qCom', namespaces, '0')),
                'valor_unitario': float(get_element_text(prod_element, 'nfe:vUnCom', namespaces, '0')),
                'valor_total_produto': float(get_element_text(prod_element, 'nfe:vProd', namespaces, '0'))
            }
            lista_produtos.append(produto)
        
        if not lista_produtos:
            print("‚ö†Ô∏è Nenhum item (<det>) encontrado na NFe.")
            return None

        return pd.DataFrame(lista_produtos)

    except ET.ParseError as e:
        print(f"‚ùå Erro de parsing no XML. O ficheiro pode estar malformado: {e}")
        return None
    except Exception as e:
        print(f"‚ùå Erro inesperado ao processar o conte√∫do do XML: {e}")
        return None

def mover_blob_para(bucket, blob, pasta_destino):
    """
    Move um blob para uma pasta de destino (erros ou processados).
    """
    try:
        now = datetime.now()
        destination_folder = f"{pasta_destino}/{now.year:04d}/{now.month:02d}"
        new_path = f"{destination_folder}/{os.path.basename(blob.name)}"
        
        bucket.copy_blob(blob, bucket, new_path)
        blob.delete()
        print(f"‚úÖ Arquivo movido para: {new_path}")
    except Exception as e:
        print(f"üî• Falha cr√≠tica ao mover o arquivo {blob.name} para {pasta_destino}. Erro: {e}")

@app.route("/", methods=["POST"])
def process_nfe_xml():
    """
    Fun√ß√£o principal, agora adaptada para o formato de payload do Eventarc (CloudEvents).
    """
    event = request.get_json(silent=True)
    if not event:
        print("‚ùå Requisi√ß√£o inv√°lida, sem payload JSON.")
        return "Requisi√ß√£o inv√°lida", 400

    print(f"üì¶ Evento recebido: {json.dumps(event)}")

    bucket_name = event.get('bucket')
    file_name = event.get('name')

    if not file_name or 'recebidas/' not in file_name:
        print(f"üìÅ Arquivo ignorado (n√£o est√° na pasta 'recebidas/'): {file_name}")
        return "Arquivo ignorado", 200
    
    if not bucket_name:
        print(f"‚ùå Erro no payload do evento: 'bucket' n√£o encontrado.")
        return "Payload do evento inv√°lido", 400

    print(f"üöÄ Processando arquivo: {file_name} do bucket: {bucket_name}")
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(file_name)

    try:
        xml_content = blob.download_as_text()
    except exceptions.NotFound:
        print(f"‚ùå Erro 404: Arquivo {file_name} n√£o encontrado no bucket. Mensagem descartada.")
        return "Arquivo n√£o encontrado, mensagem descartada", 200

    df_nfe = criar_df_nfe(xml_content)

    if df_nfe is None or df_nfe.empty:
        print(f"‚ö†Ô∏è Nenhum dado extra√≠do de {file_name}. Movendo para a pasta de erros.")
        mover_blob_para(bucket, blob, "erros")
        return "Arquivo com dados inv√°lidos ou vazios", 200

    # --- CORRE√á√ÉO: Bloco de convers√£o do CNPJ para n√∫mero foi REMOVIDO para corresponder ao esquema STRING ---

    temp_table_id = f"temp_nfe_{uuid.uuid4().hex}"
    temp_table_ref = bigquery_client.dataset(DATASET_ID).table(temp_table_id)

    try:
        job_config = bigquery.LoadJobConfig(autodetect=True, write_disposition="WRITE_TRUNCATE")
        bigquery_client.load_table_from_dataframe(df_nfe, temp_table_ref, job_config=job_config).result()
        print(f"üíæ Dados carregados na tabela tempor√°ria: {temp_table_id}")

        merge_query = f"""
            MERGE `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}` AS T
            USING `{PROJECT_ID}.{DATASET_ID}.{temp_table_id}` AS S
            ON T.CNPJ = S.CNPJ AND T.numero_nf = S.numero_nf AND T.Descricao = S.Descricao
            WHEN NOT MATCHED THEN
              INSERT (numero_nf, data_emissao, emitente, CNPJ, Descricao, Quantidade_pcs, Quantidade_kg, valor_unitario, valor_total_produto)
              VALUES(S.numero_nf, S.data_emissao, S.emitente, S.CNPJ, S.Descricao, S.Quantidade_pcs, S.Quantidade_kg, S.valor_unitario, S.valor_total_produto);
        """
        
        merge_job = bigquery_client.query(merge_query)
        merge_job.result()

        if merge_job.errors:
            print(f"‚ùå Erros ao executar MERGE: {merge_job.errors}")
            mover_blob_para(bucket, blob, "erros")
        else:
            print(f"‚úÖ MERGE conclu√≠do com sucesso para o arquivo {file_name}.")
            mover_blob_para(bucket, blob, "processados")
        
        return "Processamento finalizado", 200

    except Exception as e:
        print(f"üî• Erro cr√≠tico durante o processo de BigQuery: {str(e)}")
        mover_blob_para(bucket, blob, "erros")
        return f"Erro interno no BigQuery: {str(e)}", 200

    finally:
        bigquery_client.delete_table(temp_table_ref, not_found_ok=True)
        print(f"üóëÔ∏è Tabela tempor√°ria {temp_table_id} apagada.")

if __name__ == "__main__":
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)
